### 架构设计

1.如果用户要描述的不只是"部署一个服务"，而是希望创建多个组件(Web+Worker+Redis);每个组件具有依赖关系(先部署Redis,再部署Web);有前置初始化任务(如建表);最后需要暴露一个统一的入口(如Api Gateway);那么平台应该如何构建？

> KubeMin-Cli 会借鉴OAM模型中的"组件"思想，通过组件化的拆分，将应用由一个或者多个组件构成。这里的每个组件在部署/更新时都会转换为不同类型的Job，通过模型特征来决定系统的工作流引擎执行时是串行还是并行。
> 用户可以通过一系列编辑，最终决定组件的依赖关系，部署的先后顺序，执行哪些初始化任务或者需不需要暴露统一入口(Ingress或Istio)



2.如何将"组件之间的依赖关系+并行串行调度控制"映射为一套可执行的调度逻辑(轻量型Workflow Engine)

> 可以基于OAM模型添加一个 Workflow 的描述段：
> Workflow:
>
>   Steps:
>
> ​    -name : deploy
>
> ​     Type: deploy
>
> ​     properties:
>
> ​       policies: ["first-app-front"]
>
> 这样只要系统实现其中的Type，那么意味着工作流可以自由编排，并将这部分的业务构建放入业务层。



3.如何让其他开发团队/业务组定义自己的任务类型？是否需要提供Job类型注册机制？如何避免"所有类型的区分变为If-else?"

> 其他的开发团队或业务组可以通过Rest 风格的API 来构建工作流，但是暂时不会提供JobPlugin接口的标准，当基础的Job Type比较完善后，会考虑开放这部分标准，让更多的开发者拥有自定义的能力。



4.如果某些业务团队希望定义一个Job，比如type:ai-eval 那么如何允许他们以“最小的侵入”注册他们的处理逻辑，并且在工作流引擎中自然生效？

> 如果业务团队希望定义一个Job 我应该会先实现一个新的Job类型，比如ai-eval 来实现GPU资源挂载到Pod内，或者绑定某些云平台的Key。在多租户的场景下，我会使用多集群+命名空间的方式来对Job进行物理和虚拟化的隔离。Job执行状态我会在ack函数中写入到数据库中，以供页面展示。



5.在 AI / GPU 场景中，资源紧张非常常见。那么你平台如何：预检目标集群是否有足够 GPU？任务是否可能长时间 Pending？用户是否能看到 Job 是“失败”还是“被平台拒绝调度”？

> AI/GPU 的场景中，我可以使用GPU的异构中间件来完成GPU资源分配，任务可以通过设置超时时间来选择Pending还是结束。无论是CLi 还是Web 都会跟踪所有Job的状态变化。如果因为被平台拒绝也会提示相应的状态或展示日志。



6.当多个业务团队注册了不同类型的 Job（如 AI 训练、Helm 安装、Chaos 工程、远程 SSH 执行），你如何：管理 Job 类型的一致性（文档/验证/注册）？避免单个 Job 实现引起平台级故障？控制 Job 对外资源的访问（如挂云盘、创建 Service）？

> 当多个业务团队注册了不同类型的 Job，我可以使用分布式锁，来管理Job的一致性。整个平台会基于K8s构建，那么这意味着所有的Job都会用命名空间和Pod来执行Job，我可以设定一些故障策略来清理，记录失败的Job，而这些Job不会引起平台级别的故障。
>
> k8s中可以使用网络策略来实现Job对外资源的访问，当集群的规模足够庞大时，我可以通过使用服务网格来控制流量，可以使用云Nas来实现底层的持久化。



7.当 Job 失败率上升、队列堆积、任务延迟时：你是否可以预警平台异常（非 Job 异常）？Job 是否有统一的指标（完成时间、排队时间、成功率）？你如何暴露这些指标给监控系统（Prometheus / Grafana）？

> 可以直接在集群中部署Prometheus，然后通过Loki等日志采集等服务，对整个集群进行监控。
> Job 会设置默认的超时时间，未来会提供一系列可视化看板，比如队列中当前存在哪些任务，已完成的任务时长，成功率等。
> Job所有的执行都会通过工作流引擎全程跟踪，它们的错误日志或状态都会持久化。





### 工作流

工作流在执行时会将创建多个Job并行/串行执行，有一种场景是：

1.集群内相同命名空间内已部署一个服务。

1.1 如果仅仅只是镜像发生变化，则直接更改Deployment的镜像名

1.2 如果Deployment的元数据发生变化，是直接更改Deployment的信息比较好，还是删除后创建一个新的Deployment比较好？

> 一般是直接更改Deployment的信息，通过kubectl apply 或API的方式进行更新，Kubernetes 会自动对比并以最小的中断方式进行滚动更新。



2.如何对比两个Deployment的信息是否一致？

2.1两个Deployment以`client.AppsV1().Deployments`对象形式存在，这种场景应该如何对比？

> 对比Image 对比Pvc 对比Env 对比Sercet等信息(待定)









### 模型构建

KubeMin-Cli 项目的APP基础模型基于OAM，OAM的问题在于更适合运维人员，因为它所描述的那些特征是抽象出k8s的那些底层资源。KubeMin-Cli希望在OAM的基础上进步一降低使用的门槛，构建更加通用的数据结构，0.1版本之前只支持Json格式，以REST 风格API构建应用。



#### 特征

Traits属性用于为"组件"附加一些特性，比如为组件附加新增存储支持，新增"自定义边车容器"等特性

```Json
"traits": {
        "storage": [
          {
            "type":"persistent" //稳定存储
            "mountPath":"/data",
            "size": "20",
          },
          {
            "type":"ephemeral" //暂时存储
            "mountPath":"/data",
          },
          {
            "type":"config" //配置文件信息(限制大小)
            "name": "config-1",//
          },
          {
            "type":"secret" //密钥
            "name": "secret-1",
          },
        ],
  			"si":[]
      }


persistent 稳定存储，只有该类型设置Size类型则有效

```



| **type**   | **对应 Kubernetes 资源**            |
| ---------- | ----------------------------------- |
| persistent | PersistentVolumeClaim + VolumeMount |
| ephemeral  | emptyDir + VolumeMount              |
| config     | ConfigMap + VolumeMount 或 EnvFrom  |
| secret     | Secret + VolumeMount 或 EnvFrom     |

#### ephemeral

对于定义了 `emptyDir` 卷的 Pod，在 Pod 被指派到某节点时此卷会被创建。 就像其名称所表示的那样，`emptyDir` 卷最初是空的。尽管 Pod 中的容器挂载 `emptyDir` 卷的路径可能相同也可能不同，但这些容器都可以读写 `emptyDir` 卷中相同的文件。 当 Pod 因为某些原因被从节点上删除时，`emptyDir` 卷中的数据也会被永久删除。

`emptyDir` 的一些用途：

- 缓存空间，例如基于磁盘的归并排序。
- 为耗时较长的计算任务提供检查点，以便任务能方便地从崩溃前状态恢复执行。
- 在 Web 服务器容器服务数据时，保存内容管理器容器获取的文件。



#### config

[`configMap`](https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-pod-configmap/) 卷提供了向 Pod 注入配置数据的方法。 ConfigMap 对象中存储的数据可以被 `configMap` 类型的卷引用，然后被 Pod 中运行的容器化应用使用。

> #### 说明：
>
> - 你必须先[创建 ConfigMap](https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-pod-configmap/#create-a-configmap)， 才能使用它。
> - ConfigMap 总是以 `readOnly` 的模式挂载。
> - 某容器以 [`subPath`](https://kubernetes.io/zh-cn/docs/concepts/storage/volumes/#using-subpath) 卷挂载方式使用 ConfigMap 时， 若 ConfigMap 发生变化，此容器将无法接收更新。
> - 文本数据挂载成文件时采用 UTF-8 字符编码。如果使用其他字符编码形式，可使用 `binaryData` 字段。





### 插件设计

插件系统的核心需要定义插件的接口，并负责管理和调用这些插件。

```go
// TraitProcessor is the interface for all trait processors.
type TraitProcessor interface {
	Name() string
	Process(workload interface{}, traitData interface{}, component *model.ApplicationComponent) error
}
```







工作流的设计在于如何更好地执行某一类型的任务，但是里面会有一个问题，有些任务不需要回调，有些任务则需要回调函数，有些任务是异步的，有些任务是需要及时返回的。应对这种类繁多的Job解决方案如下：

1.异步，不需要回调

任务请求通过现有的工作流执行，通过数据库的Job执行状态来判断是否最终执行成功。这类方式适合：不确定任务的执行时间的情况下使用，比如部署应用，执行脚本任务，某些一次性任务等。这些任务只需要记录是否执行成功，最终记录Job的执行状态。

2.异步，需要回调。

新增Job的类型即可，因为整个过程是异步的，可以通过上下文将整个任务全部记录下来，最终写到数据库，或消息中间件中。

2.1如果需要写到数据库中，那么就需要给予用户一个查询整个记录信息，可以通过API查询数据中所记录的日志信息

2.2如果写入消息中间件中，则可以做一些消息推送机制，比如另外一个服务用于接受kafka中的消息，然后通过ws主动推送到客户端。但是这种方式前期投入到成本要比第一种方式要高。它的好处在于易于扩展，可以基于不同的场景做更多的适配。

3.同步，不需要回调。

通过新增Job的类型即可实现，因为整个过程是同步的，用户可以基于这种方式执行一些轻量级任务，又因为用户可能不需要回调的信息，可以直接通过API风格的接口包装一层，直接使用封装好的函数执行一些通用命令。但是这里要注意默认框架的超时时间，在高并发的场景下可能会频繁超时。

为了避免高并发场景下的频繁执行，这里可能需要引入一些限流的机制，或任务池。

4.同步，需要回调用。

直接通过接口去实现，比如查询日志这种情况，可以封装成一个新的接口，然后实现不同的返回信息。客户端可以与服务端建立一个SSE，也可以建立一个WS服务，及时交换信息。

```
                   +-----------------------+
                   |        Job            |
                   +-----------------------+
                          |         |
                     +----+         +----+
                     |                    |
                Async Job             Sync Job
                 |    |                |     |
       +---------+    +----------+     |     +----------+
       |                       |       |                |
 No Callback           Need Callback  No CB        Need Callback
   |                         |         |               |
 DB记录状态       Kafka/WS 推送日志     API返回      SSE/WS 实时返回
```



